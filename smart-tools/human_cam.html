<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>تشخیص هویت (چهره و بدن)</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: black; font-family: sans-serif; }
        canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; }
        #ui-layer { position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; z-index: 10; }
        .back-btn {
            position: absolute; top: 20px; left: 20px; pointer-events: auto;
            background: rgba(0,0,0,0.6); color: white; padding: 10px 20px;
            border: 1px solid white; border-radius: 20px; text-decoration: none; font-size: 14px;
        }
        .controls {
            position: absolute; top: 20px; right: 20px; pointer-events: auto;
            background: rgba(0,0,0,0.5); padding: 10px; border-radius: 10px; color: white;
            display: flex; align-items: center; gap: 10px;
        }
        #status-msg {
            position: absolute; top: 80px; width: 100%; text-align: center;
            color: yellow; font-size: 18px; text-shadow: 1px 1px 2px black;
        }
        #error-log {
            position: absolute; bottom: 10px; left: 10px; width: 90%; 
            color: red; font-size: 12px; background: rgba(0,0,0,0.8); 
            padding: 5px; display: none; z-index: 20; text-align: left; direction: ltr;
        }
    </style>
    <script src="./assets/tf-core.js"></script>
    <script src="./assets/tf-converter.js"></script>
    <script src="./assets/tf-backend-webgl.js"></script>
    <script src="./assets/pose-detection.js"></script>
</head>
<body>
    <video id="video" playsinline style="display: none;"></video>
    <canvas id="output"></canvas>
    <div id="ui-layer">
        <a href="index.html" class="back-btn">BACK</a>
        <div class="controls">
            <input type="range" id="threshold" min="0" max="100" value="50">
            <span id="thresh-val">حساسیت: 50%</span>
        </div>
        <div id="status-msg">...در حال بارگذاری مدل آفلاین...</div>
        <div id="error-log"></div>
    </div>
    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('output');
        const ctx = canvas.getContext('2d');
        const statusMsg = document.getElementById('status-msg');
        const errorLog = document.getElementById('error-log');
        let detector;

        function logError(err) {
            console.error(err);
            statusMsg.innerText = "خطا در اجرا";
            errorLog.style.display = 'block';
            errorLog.innerText = err;
        }

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: 'environment', width: 640, height: 480 }, audio: false
            });
            video.srcObject = stream;
            return new Promise((resolve) => { video.onloadedmetadata = () => { video.play(); resolve(video); }; });
        }

        async function loadModel() {
            try {
                await tf.ready();
                // آدرس دهی دقیق به فایل لوکال
                const modelConfig = {
                    modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING,
                    modelUrl: './assets/movenet/model.json' 
                };
                detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, modelConfig);
                statusMsg.innerText = ""; 
                detectPose();
            } catch (e) {
                logError("Error Loading Model: " + e.message + " (Check assets/movenet folder)");
            }
        }

        async function detectPose() {
            if (!detector) return;
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            try {
                const poses = await detector.estimatePoses(video);
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                if (poses && poses.length > 0) {
                    const keypoints = poses[0].keypoints;
                    const threshold = document.getElementById('threshold').value / 100;
                    keypoints.forEach(kp => {
                        if (kp.score > threshold) {
                            ctx.beginPath();
                            ctx.arc(kp.x, kp.y, 5, 0, 2 * Math.PI);
                            ctx.fillStyle = '#00ff00';
                            ctx.fill();
                        }
                    });
                }
            } catch (err) {}
            requestAnimationFrame(detectPose);
        }

        (async function main() {
            try { await setupCamera(); await loadModel(); } catch(e) { logError(e); }
        })();
    </script>
</body>
</html>
