<!DOCTYPE html>
<html>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <style>body{margin:0;background:black;overflow:hidden} video,canvas{position:absolute;width:100%;height:100%}</style>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@3.18.0/dist/tf-backend-webgl.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@2.0.0/dist/pose-detection.js"></script>
</head>
<body>
    <video id="v" playsinline muted autoplay></video>
    <canvas id="c"></canvas>
    <script>
        async function run() {
            const v = document.getElementById('v');
            const c = document.getElementById('c');
            const ctx = c.getContext('2d');
            
            const stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'}});
            v.srcObject = stream;
            await new Promise(r => v.onloadedmetadata = r);
            v.play();
            c.width = v.videoWidth; c.height = v.videoHeight;

            await tf.ready();
            const detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, {modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING});

            async function frame() {
                const poses = await detector.estimatePoses(v);
                ctx.clearRect(0,0,c.width,c.height);
                poses.forEach(p => {
                    p.keypoints.forEach(k => {
                        if(k.score > 0.3) {
                            ctx.beginPath(); ctx.arc(k.x, k.y, 8, 0, 2*Math.PI);
                            ctx.fillStyle = '#00ff00'; ctx.fill();
                        }
                    });
                });
                requestAnimationFrame(frame);
            }
            frame();
        }
        run();
    </script>
</body>
</html>